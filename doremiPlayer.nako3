/*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*
　ドレミプレーヤー - 再生専用(doremiPlayer.nako3)

　Web Audio APIで、ドレミ演奏データ(JSONさん)を再生するだけのやつ
　doremi.nako3の演奏命令だけを抜き出したもの

※音色のテスト用
※カスタム波形のテスト
*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*/

#------------------------------------------------
＃ ドレミ演奏命令
#------------------------------------------------
●(ドレミを|ドレミの)ドレミ演奏
    A＝オーディオコンテキスト作成。
    もし、(ドレミの変数型確認)≠「object」ならば、「MMLを直接演奏する場合は『doremi.nako3』を使用してください」と表示。
    Aでドレミをドレミデータ演奏。
    Aを戻す。
ここまで。

# Aはオーディオコンテキストを指定する
●(Aを|Aの)ドレミ演奏停止
    もし、(A≠NULL)ならば、:
        もし、(A["state"]≠「closed」)ならば、:
            Aの「close」を[]でJSメソッド実行。
ここまで。

●(Aを|Aの)ドレミ演奏一時停止
    もし、A≠NULLならば、Aの「suspend」を[]でJSメソッド実行。
ここまで。

●(Aを|Aの)ドレミ演奏再開
    もし、A≠NULLならば、Aの「resume」を[]でJSメソッド実行。
ここまで。
#------------------------------------------------
＃＃ドレミ演奏の内容
# まずオーディオコンテキストを作る
●オーディオコンテキスト作成
    「new AudioContext()||webkitAudioContext()」をJS実行。
ここまで。

# 演奏データを再生する
# Aはオーディオコンテキスト
●(Aでドレミデータを|ドレミデータの)ドレミデータ演奏
    ドレミデータのドレミ情報描画。
    ドレミデータ["データ"]を反復:
      もし、対象["音量"]＞0ならば、:

        Aに対象で音色準備処理。

    Aとドレミデータのドレミ演奏タイマー。
ここまで。
#------------------------------------------------
＃ドレミデータ演奏の下請け
＃＃タイマー
●(Aとドレミデータの)ドレミ演奏タイマー
    Cとは変数。字幕データとは変数。
    もし、(ドレミデータ["情報"]["字幕設定"]≠NULL)かつ(ドレミデータ["字幕データ"]≠NULL)ならば、:
        C＝ドレミデータ["情報"]["字幕設定"]["カウンタ"]。
        字幕データ＝ドレミデータ["字幕データ"][C]。
    もし、A＝NULLならば、:
        もし、字幕データ≠NULLならば、ドレミデータ["情報"]["字幕設定"]["カウンタ"]＝0。
        戻る。
    違えば、もし、A["currentTime"]＞(ドレミデータ["情報"]["曲長"]＋2)ならば、:
        Aをドレミ演奏停止。
        戻る。
    違えば、もし、字幕データ≠NULLならば、:
        もし、A["currentTime"]＞字幕データ["時間"]ならば、:
            ドレミデータのCをドレミ字幕描画。
            ドレミデータ["情報"]["字幕設定"]["カウンタ"]を１増やす。。
    0.01秒待つ。
    Aとドレミデータのドレミ演奏タイマー。
ここまで。

＃＃字幕描画
●(ドレミデータのNoを)ドレミ字幕描画
    変数 字幕設定＝ドレミデータ["情報"]["字幕設定"]。
    変数 字幕データ＝ドレミデータ["字幕データ"][No]
    変数 x＝字幕設定["描画X"]。変数 y＝字幕設定["描画Y"]。
    変数 文字＝字幕データ["文字"]。変数 改行数＝字幕データ["改行"]。
    字幕設定["歌詞"]["カラオケ文字色"]に塗り色設定。
    字幕設定["歌詞"]["文字サイズ"]に描画フォント設定。
    変数 文字幅＝文字の文字幅取得。
    変数 文字高さ＝「あ」の文字高さ取得。
    文字高さ＝文字高さ+文字高さ/4。
    [x,y]へ文字を文字描画。
    字幕設定["描画X"]＝x+文字幅。
    もし、改行数＞０ならば、:
        字幕設定["描画X"]＝字幕設定["歌詞"]["X"]。
        字幕設定["描画Y"]＝y+文字高さ*改行数。
ここまで。

●(ドレミデータの)ドレミ情報描画
    変数 ドレミ情報＝ドレミデータ["情報"]
    変数 字幕設定＝ドレミ情報["字幕設定"]。
    もし、字幕設定＝NULLならば、戻る。
    「曲名,作者」を「,」で区切って反復:
        もし、ドレミ情報[対象]＝NULLならば、続ける。
        変数 x＝字幕設定[対象]["X"]。変数 y＝字幕設定[対象]["Y"]。
        字幕設定[対象]["文字色"]に塗り色設定。
        字幕設定[対象]["文字サイズ"]に描画フォント設定。
        [x,y]へドレミ情報[対象]を文字描画。
    「コメント,歌詞」を「,」で区切って反復:
        もし、ドレミ情報[対象]＝NULLならば、続ける。
        x＝字幕設定[対象]["X"]。y＝字幕設定[対象]["Y"]。
        字幕設定[対象]["文字色"]に塗り色設定。
        字幕設定[対象]["文字サイズ"]に描画フォント設定。
        変数 文字高さ＝「あ」の文字高さ取得。
        文字高さ＝文字高さ+文字高さ/4。
        ドレミ情報[対象]を改行で区切って反復:
            [x,y]へ対象を文字描画。
            y＝y+文字高さ。
ここまで。

＃＃＃文字描画幅取得
●(Aの)文字幅取得
　　TM＝Aの文字描画幅取得。
　　TM["width"]で戻る。
ここまで。
●(Aの)文字高さ取得
　　TM＝Aの文字描画幅取得。
　　TM["actualBoundingBoxAscent"]+TM["actualBoundingBoxDescent"]で戻る。
ここまで。

＃＃ウェブオーディオAPI
●(オーディオコンテキストにデータで)音色準備処理とは
	オシレータ＝オーディオコンテキストの「createOscillator」を[]でJSメソッド実行。
	ゲイン＝オーディオコンテキストの「createGain」を[]でJSメソッド実行。
	ステレオパン＝オーディオコンテキストの「createStereoPanner」を[]でJSメソッド実行。

    # 音量設定
    音量＝データ["音量"]。
    開始時間＝データ["開始時間"]。
    停止時間＝データ["停止時間"]。
    ゲイン["gain"]の「setValueAtTime」を[音量,開始時間]でJSメソッド実行。

    # 音色設定
    ## 波形
    音色＝データ["音色"]。音番号＝データ["音番号"]。
    もし、音色＜１ならば、音色＝５。
    波形タイプ＝(音色-1)%8。
    波形タイプで条件分岐:
        0ならば、オシレータ["type"]＝「sine」。音量＝音量*1.3。。。
        1ならば、オシレータ["type"]＝「square」。音量＝音量*0.7。。。
        2ならば、オシレータ["type"]＝「sawtooth」。音量＝音量*0.8。。。
        3ならば、オシレータ["type"]＝「triangle」。音量＝音量*1.2。。。
        違えば、
            real＝空配列。imag＝空配列。real[0]＝0。imag[0]＝0。
            波形データ＝[
                [[0,1],[0,0.5],[0,0],[0,0],[0,0.1],[0,0],[0,0.2],[0,0],[0,0.2],[0,0]],
                [[0,1],[0,1],[0,0.5],[0,0],[0,0],[0,0],[0,0],[0,0],[0,0],[0,0]],
                [[0,0.5],[0,0],[0,0],[0,0.8],[0,0],[0,0.2],[0,0],[0,0],[0,0],[0,0]],
                [[1,1],[0,0],[0,0],[0,0],[0,0],[0,0],[0,0],[0,0.2],[0,0],[0,0.2]]
            ]
            波形データ[波形タイプ-4]を反復:
                real[対象キー+1]＝対象[0]。imag[対象キー+1]＝対象[1]。
                wave＝ オーディオコンテキストの「createPeriodicWave」を[real, imag]でJSメソッド実行。
                オシレータの「setPeriodicWave」を[wave]でJSメソッド実行。
        ここまで。
    ## 減衰・余韻
    音色データ＝[[0,0.8],[1,1.5,1],[2,0.5,NULL,-12],[3,0.3],[3,0.1,NULL,-24],[2,1,NULL,NULL,10],[2,0.8],[2,0.5,NULL,-24,5],[2,0.2],[2,0.2,NULL,NULL,10],[2,2,NULL,24],[4,1,NULL,-24,5],[4,1.5,NULL,24,5],[1,1,1,12],[1,0.5,0.5],[1,2,2,24,10]]
    系統＝(音色-1)/8を整数変換。

    減衰パターン,余韻,発声時間,デチューン,揺れ＝音色データ[系統]。
    もし、余韻＝オフならば、余韻＝0.1。
    音長＝停止時間-開始時間。

    減衰パターンで条件分岐
    　0ならば、//ピアノ系
        ゲイン["gain"]の「exponentialRampToValueAtTime」を[音量*0.8,開始時間+(停止時間-開始時間)/2]でJSメソッド実行。
        ゲイン["gain"]の「exponentialRampToValueAtTime」を[(音量*0.1)/音長,停止時間]でJSメソッド実行。
        ゲイン["gain"]の「exponentialRampToValueAtTime」を[0.00001,停止時間+余韻]でJSメソッド実行。
    　ここまで。
    　1ならば、//クロマチック系、ベル、鐘
        もし、発声時間＞音長ならば、発声時間＝音長。
        ゲイン["gain"]の「exponentialRampToValueAtTime」を[0.00001,開始時間+発声時間+余韻]でJSメソッド実行。
    　ここまで。
    　2ならば、//減衰しない。オルガン系、ストリングス系、パイプ系など
        ゲイン["gain"]の「setValueAtTime」を[音量,停止時間]でJSメソッド実行。
        ゲイン["gain"]の「exponentialRampToValueAtTime」を[0.00001,停止時間+余韻]でJSメソッド実行。
    　ここまで。
    　3ならば、//ギター系
    　　発声時間＝音量＊8。
    　　もし、発声時間＞音長ならば、発声時間＝音長-音長/8。
        ゲイン["gain"]の「exponentialRampToValueAtTime」を[音量*0.5,開始時間+発声時間]でJSメソッド実行。
        ゲイン["gain"]の「exponentialRampToValueAtTime」を[(音量*0.1)/音長,停止時間]でJSメソッド実行。
        ゲイン["gain"]の「exponentialRampToValueAtTime」を[0.00001,停止時間+余韻]でJSメソッド実行。
    　ここまで。
    　4ならば、//パッド系、SFX系とか？
        ゲイン["gain"]の「exponentialRampToValueAtTime」を[音量*0.5,開始時間+(停止時間-開始時間)/2]でJSメソッド実行。
        ゲイン["gain"]の「exponentialRampToValueAtTime」を[(音量*0.3)/音長,停止時間]でJSメソッド実行。
        ゲイン["gain"]の「exponentialRampToValueAtTime」を[0.00001,停止時間+余韻]でJSメソッド実行。
    　ここまで。
    ここまで。

    ## デチューン
    もし、デチューン≠NULLならば、
        オシレータ["detune"]の「setValueAtTime」を[デチューン,開始時間]でJSメソッド実行。
        オシレータ["detune"]の「linearRampToValueAtTime」を[0,停止時間]でJSメソッド実行。
    ここまで。
    # 方向
    変数 方向＝データ["方向"]。
    もし、方向＝「回転」ならば、
    	ステレオパン["pan"]の「setValueAtTime」を[-1,開始時間]でJSメソッド実行。
    	ステレオパン["pan"]の「linearRampToValueAtTime」を[1,開始時間+(停止時間-開始時間)/2]でJSメソッド実行。
    	ステレオパン["pan"]の「linearRampToValueAtTime」を[-1,停止時間]でJSメソッド実行。
    違えば、
        もし、方向＝NULLならば、方向＝0。
    	ステレオパン["pan"]の「setValueAtTime」を[方向,開始時間]でJSメソッド実行。
    ここまで。
    # 接続
    オシレータの「connect」を[ゲイン]でJSメソッド実行。
    それの「connect」を[ステレオパン]でJSメソッド実行。
    それの「connect」を[オーディオコンテキスト["destination"]]でJSメソッド実行。

    もし、(データ["ビブラート"]≠NULL)または(揺れ≠NULL)ならば、
        もし、データ["ビブラート"]≠NULLならば、揺れ＝データ["ビブラート"]
        ビブラート＝オーディオコンテキストの「createOscillator」を[]でJSメソッド実行。
        ビブラート["frequency"]["value"]＝揺れ。
    	ビブラートゲイン＝オーディオコンテキストの「createGain」を[]でJSメソッド実行。
        ビブラートゲイン["gain"]＝20。
        ビブラートの「connect」を[ビブラートゲイン]でJSメソッド実行。
        それの「connect」を[オシレータ["frequency"]]でJSメソッド実行。
        ビブラートの「start」を[開始時間]でJSメソッド実行。
        ビブラートの「stop」を[停止時間+余韻]でJSメソッド実行。
    ここまで。

    # 発声
    オシレータ["frequency"]["value"]＝音番号を周波数変換処理。
    オシレータの「start」を[開始時間]でJSメソッド実行。
    オシレータの「stop」を[停止時間+余韻]でJSメソッド実行。
ここまで。

＃＃音番号を周波数に変換する式
●(音番号を)周波数変換処理とは
    440*(2^((音番号-69)/12))で戻る。
ここまで。
#------------------------------------------------